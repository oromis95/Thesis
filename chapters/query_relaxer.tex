\section{Algoritmo Progettato}
In questa sezione saranno illustrati sequenzialmente i passi effettuati dal software. I passi sono  seguenti:
\begin{itemize}[noitemsep]
    \item Caricamento dataset
    \item Caricamento lista RFD
    \item Ordinamento delle RFD
    \item Query Estesa
    \item Query Rilassata
\end{itemize}
\paragraph{Caricamento Dataset}
Il primo passo da effettuare è quello di caricare il Dataset in formato csv. Il separatore che di norma può essere costituito da un carattere a scelta è stato impostato come carattere ";".\\ Il dataset può contenere vari tipi di dati: float, int, stringhe e date.
La struttura dati utilizzata per contenere i dati è quella del pandas.Dataframe , contenuta nel package Pandas\footnote{Pandas è una libreria software scritta per il linguaggio di programmazione Python .È adibita alla manipolazione e l'analisi dei dati. In particolare, offre strutture e operazioni di dati per la manipolazione di tabelle numeriche e di serie temporali. }. \\Il Dataframe di Pandas è una struttura dati tabulare bidimensionale variabile in formato, potenzialmente eterogenea e con assi etichettati (righe e colonne). Le operazioni vengono effettuate sulle rige e sulle colonne. 
\paragraph{Carimento lista RFD}
Il secondo passo consiste nel caricare la lista di RFD. L'utente può passare il path del file contenente le RFD, altrimenti viene invocato un algoritmo di ricerca di RFD sul Dataset indicato.
Nel caso in cui venga passato il path, il formato del file deve essere di tipo csv, con carattere di separazione uguale a ";".
Dato che ogni RFD può avere un attributo diverso come parte RHS , si è scelto di utilizzare una particolare notazione:
\begin{table}[H]
    \centering
    \begin{tabular}{l l l l l }
     RHS & $attr_1$ & $attr_2$ & $attr_{\ldots}$ & $attr_n$ \\
    $attr_{k}$ & $s_{12}$ & $s_{13}$ & $s_{\ldots}$ & $s_1n$  \\
    $attr_{j}$ & $s_{22}$ & $s_{23}$  & $s_{\ldots}$ & $s_{2n}$\\
    $attr_{p}$ & $s_{\ldots1}$ & $s_{\ldots3}$  & $s_{\ldots}$ & $attr_{r}$\\
    $s_{m1}$ & $s_{m2}$ & $s_{m3}$ & $s_{\ldots}$ & $s_{mn}$\\
    \end{tabular}
    \caption{Pandas Dataframe contenente le soglie delle RFD}
    \label{tab:RFD_notation}
\end{table}

La prima colonna del Dataframe contiene non una soglia bensì il nome dell'attributo che funge da RHS in quella RFD.
\\
Se l'utente non fornisce il path del file, o il file non viene trovato, il software richiama l'algoritmo di ricerca delle RFD. Viene passato all'algoritmo di RFDD\footnote{Relaxed Functional Dependencies Discovery} il path del dataset, l'algoritmo dopo aver elaborato restituisce una Dataframe contenente le RFD, le quali vengono salvate su file e dopodichè caricate in memoria.
\paragraph{Ordinamento delle RFD}
Una volta caricata la lista di query è necessario effettuare una pulizia sui dati.
Vengono eliminate le RFD che valore "Nan" su attributi che sono presenti nella query, dopodiché vengono eliminate le RFD dove nel lato RHS è presente un attributo della query \footnote{Utilizzare una RFD di questo tipo significherebbe utilizzare una dipendenza funzionale rilassata banale, la quale non porta alcuna informazione aggiuntiva}
Dopo aver effettuato questa pulizia le RFD vengono ordinate. 
\newline
C'è stata molta indecisione riguardo l'implementazione dell'ordinamento, in quanto non è stata trovata una dimostrazione formale che ci indicasse quale metodo fosse il più efficace.
L'obiettivo è stato quello di trovare un algoritmo che ordinasse le RFD dando precedenza a quelle che producono Result Set non troppo ampi.
\\
Dopo vari test abbiamo pervenuto che il metodo più efficacie fosse quello di ordinare le RFDs prima in ordine decrescente rispetto al numero di attributi con valore "Nan" e poi in ordine crescente di soglia rispetto agli attributi presenti nella query. 
L'ordinare secondo soglie più piccole indica che quelle RFD agiscono su range ridotti, indicativamente ciò significa che in dato rispetto ad un range più ampio un range di dimensioni ridotte include meno dati .In realtà può capitare che in un Dataset vi sia un aggregazione di dati un piccolo range superiore a tutti gli altri dati presenti nel Dataset, ad esempio preso un Dataset che possiede un attributo altezza possiamo avere i seguenti valori
\begin{table}[H]
    \centering
    \begin{tabular}{l }
    altezza \\
    170 \\
    171 \\
    172 \\
    171 \\
    169 \\
    170 \\
    173 \\
    170 \\
    169 \\
    158 \\
    165 \\
    152 \\
    \end{tabular}
    \caption{Esempio di valori su attributo altezza}
    \label{tab:height_list}
\end{table}
In questo caso se abbiamo due range $[169,172]$ e $[140,165]$, l'intuizione ci dice che il primo range essendo il più piccolo dovrebbe includere meno dati, invece guardando dalla lista si può notare che il primo range contiene 8 valori ed il secondo solo 3.
Ciò capita abbastanza raramente , infatti nei test effettuati questo principio di ordinamento ha restituito quasi sempre i risultati migliori.
Per aumentare l'efficacia dell'ordinamento abbiamo ritenuto necessario dare precedenza alle RFD che nel lato LHS possiedono un numero di attributi il più simile possibile agli attributi presenti nella query.
Nella tabella sottostante viene mostrata parte di una lista di RFD ordinata \footnote{L'ordinamento è stato effettuato in base ad una query eseguita dall'utente, in questo caso la query è SELECT * FROM dataset{\_}string WHERE height=169}:
\begin{table}[H]
    \centering
    \begin{tabular}{l l l l l l l l}
        & RHS & age & height & shoe{\_}size & weight \\
        \hline
    0 & shoe{\_}size & NaN & 0.0 & 1.0 & NaN \\
    1 & weight & NaN & 0.0 & 0.0 & 1.0 \\
    2 & shoe{\_}size & 3.0 & 0.0 & 0.0 & NaN \\
    3 & weight & 6.0 & 1.0 & NaN & 4.0 \\
    4 & weight & NaN & 1.0 & 1.0 & NaN \\
    5 & shoe{\_}size & 6.0 & 1.0 & 1.0 & NaN \\
    6 & shoe{\_}size & NaN & 1.0 & 1.0 & 4.0 \\
    7 & shoe{\_}size & NaN & 1.0 & 0.0 & 2.0 \\
    8 & age & 6.0 & 1.0 & 0.0 & NaN \\
    9 & age & 5.0 & 1.0 & 1.0 & NaN \\
    \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
    \end{tabular}
    \caption{Parte di una lista di RFD ordinata}
    \label{tab:ord_rdf}
\end{table}

\paragraph{Query Estesa}
D'ora in poi tutta la procedura descritta da qui in avanti verrà iterata per un numero di RFD pari ad un valore definito dall'utente. \footnote{In caso in cui l'utente lasci il campo vuoto, l'iterazione viene effettuata per ogni RFD presente nella lista}
Viene selezionata la i-esima RFD con $i\in[1,n]$. 
Si vanno a considerare gli attributi della RFD che siano presenti nella query\footnote{In questo momento si considerano solo gli attributi in LHS}, si prendono le soglie e si effettua una nuova una query estesa $Q_2$
Ad esempio supponendo che la query iniziale sia: \\~\\ \centerline{SELECT * FROM dataset{\_}string WHERE height=169} \\~\\ e che la RFD selezionata sia: \\~\\ \centerline{$(height \leq 0.0)  \rightarrow(shoe_size \leq 0.0)$} \\~\\
Viene effettuato un controllo sul tipo di valori degli attributi della query,
si vanno a identificare string, int e float, questa identificazione serve a specificare quale funzione di distanza bisogna applicare durante l'estensione della query.
Dato che height è un attributo di tipo numerico, si vanno a prendere tutti i valori che differiscono di 0 dal valore iniziale inserito dall'utente. In questo caso la query estesa $Q_2$ resta uguale a $Q_1$: \newline 
\centerline{SELECT * FROM dataset{\_}string WHERE height =169} \newline
Effettuando una nuova interrogazione con la query $Q_2$ otteniamo un Result Set che sarà di sicuro $\geq$ del Result Set restituito dall query iniziale
In questo caso entrambe le query restituiscono questo risultato: \newline 
\begin{table}[H]
    \centering
    \begin{tabular}{l l l l l l l l}
    n.row   & height & weight & shoe{\_}size & age \\
    \hline
    5 & 169 & 73 & 38 & 49 \\

    \end{tabular}
    \caption{Result Set restituito sia dalla query $Q_1$ e sia dalla query $Q_2$ }
    \label{tab:sta_ext_result_set}
\end{table}
\paragraph{Query Rilassata}
In questa procedura viene effettuato il vero e proprio rilassamento, scambiando gli attributi della query con attributi definiti dalla parte RHS della RFD selezionata (vedi Appendice [perfezionamento con lhs]).
Inizialmente si effettua una raccolta dei valori nel dataset, si selezionano solo gli attributi che sono presenti in RHS. Viene mantenuta una struttura dati \footnote{In questo momento lo definiamo come un set} per ogni tupla restituita dal dataset (vedi Appendice [perfezionamento combinazioni]). 
Per ogni set vengono rilassati i valori in base alle soglie contenute nella RFD, i risultato sarà una serie si SET che contengono dei range più ampi.
È quindi possibile effettuare k query rilassate, ottenendo vari Result Set. La loro unione andrà a costituire il Result Set finale che sarà restituito in output.
Riprendendo l'esempio riportato nel paragrafo precedente, vengono raccolti i dati sui valori presenti in RHS, in questo caso vi è solo l'attributo shoe{\_}sie \footnote{In realtà in RHS vi è sempre un unico attributo, la query viene rilassata con più attributi in quanto si esegue un perfezionamento vedi  Appendice [perfezionamento combinazioni]} che viene rilassato di una soglia pari a 0. Dato che la query estesa $Q_2$ ha restituito una sola tupla, verrà rilassato un unico valore. La query rilassata $Q_3$  è : \newline 
\centerline{SELECT * FROM dataset{\_}string WHERE shoe{\_}size=38}
\newline
Per la proprietà delle RFD (vedi Appendice Proprietà RFD) il Result Set restituito sarà $\geq$ del Result Set restituito dalla query estesa $Q_2$.

In questo caso il Result Set è uguale a :
\begin{table}[H]
    \centering
    \begin{tabular}{l l l l l l l l}
    n.row  & height & weight & shoe{\_}size & age \\
    \hline
    0  & 175 & 75 & 39 & 41 \\
    1  & 169 & 73 & 38 & 49 \\
    2  & 170 & 65 & 39 & 30 \\
    \end{tabular}
    \caption{Result Set restituito sia dalla query $Q_3$ }
    \label{tab:relax_result_set}
\end{table}

Dato che questa procedura viene effettuata per un numero N di RFD, viene effettuato un confronto in modo tale da restituire il Result Set che che sia il meno ampio possibile \footnote{Vengono scartati i Result Set che hanno cardinalità uguale ad Result Restituito dalla query iniziale}

\section{Struttura del Progetto}
Il progetto è incluso in una cartella contenente anche il software di ricerca di RFD, tutto il codice sviluppato è contenuto nella sottocartella query{\_}rewriter
\begin{figure}[H]
    \centering
    \includegraphics{struct_project.png}
    \caption{Struttura del Progetto}
    \label{fig:struct_project}
\end{figure}

\subsection{Package Dataset}
Il package Dataset include una serie di Dataset in formato csv ed una cartella contente le rispettive liste di RFD già precalcolate. 
I Dataset inclusi nel progetto sono:
\begin{itemize}[noitemsep]
\let\labelitemi\labelitemii
    \item cars.csv
    \item cars2.csv
    \item cars{\_}db.csv
    \item cora.csv
    \item crawled-tweets.csv
    \item dataset.csv
    \item dataset{\_}string.csv
    \item dataset{\_}string2.csv
    \item echocardiogram.csv
    \item iris.csv
    \item restaurant
\end{itemize}

Sono state già calcolate le seguenti liste di RFD:
\begin{itemize}[noitemsep]
\let\labelitemi\labelitemii
    \item cars{\_}db{\_}rfds.csv
    \item cars{\_}rfds.csv
    \item cora{\_}rfds.csv
    \item dataset{\_}rdfs.csv
    \item dataset{\_}strng{\_}rdfs.csv
\end{itemize}


La maggior parte dei Dataset sono in formato numerico, ma ne sono presenti alcuni che possiedono attributi sia in formato numerico che di tipo stringa

\subsection{Package io}
In questo package sono contenuti diversi moduli divisi in baso al loro scopo. Vi sono due sottocartelle che raggruppano il tutto.
Il contenuto nella sottocartela csv comprende:
\begin{itemize}[noitemsep]
\let\labelitemi\labelitemii
    \item csv{\_}parser.py
    \item io.py
\end{itemize}

\paragraph{csv{\_}parser.py}
Questo modulo contiene la classe CSV Parser che si occupa di prendere i dati dai file CSV e salvarli in un dataframe, il tutto viene fatto nel metodo init.
\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
class CSVParser:
    def __init__(self, csv_path: str):
        self.path = csv_path
        self.delimiter = self.__guess_delimiter()
        self.data_frame = pd.read_csv(self.path, 
                                delimiter=self.delimiter)
        self.rows_count, self.columns_count = self.data_frame.shape
        self.header = list(self.data_frame)
\end{minted}
\caption{Class CSVParser}
\label{Code:1}
\end{listing}
L'operazione vera e propria di parsing e loading dei dati viene delegata al Framework Pandas, richiamando il metodo alla riga 5
Le variabili di questa classe sono:
\begin{itemize}[noitemsep]
    \item path:[str] Contiene il path del file CSV
    \item delimiter:Contiene il carattere di separazione
    \item data{\_}frame:[Pandas Dataframe] Contiene i dati del file CSV letto
    \item rows{\_}count:[int]contiene il numero di righe contenute nel file CSV
    \item column{\_}count:[int]contiene il numero di colonne contenute nel file CSV
    \item header:[list] contiene una lista di valori che fungono da header, questi valori sono specificati nella prima riga del file csv
\end{itemize}
L'unico argomento da passare al costruttore è il path del file, tutti gli altri dati vengono calcolati. 
All'interno del costruttore è presente una chiamata al metodo {\_\_}guess{\_}delimiter:

\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
    def __guess_delimiter(self):
\end{minted}
\caption{Guess delimiter}
\label{Code:2}
\end{listing}

Questo metodo ha il compito di indovinare il carattere di separazione leggendo il file.

\paragraph{io.py}
Questo modulo contiene la classe CSVInputOutput la quale si occupa di importare/esportare una Pandas.Dataframe da/in un file CSV
\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
    class CSVInputOutput:
\end{minted}
\caption{CSVInputOutput}
\label{Code:3}
\end{listing}
Le variabili di questa classe sono:
\begin{itemize}[noitemsep]
    \item sep:[str] campo contenente il simbolo di separazione utilizzato nei file CSV
    \item na{\_}rep:[str] campo contenente il simbolo che rappresenta un dato mancante 
    \item index:[boolean] flag che indica se si vuole stampare nel file csv gli indici di riga
    \item encoding:[str] campo contente la codifica dei file input/output
    \item date{\_}format:[str] campo contente il formato delle date
\end{itemize}
Questa classe possiede due metodi.
Il primo è il metodo store
\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
    def store(self, df: pd.DataFrame, path: str):
\end{minted}
\caption{store method}
\label{Code:4}
\end{listing}
Questo metodo prende in input il path del del file in cui andare a salvare il DataFrame

Il secondo è il metodo load
\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
    def load(self, path: str) -> pd.DataFrame:
\end{minted}
\caption{load method}
\label{Code:5}
\end{listing}
Il metodo prende in input il path del file e delegando a Pandas Dataframe esegue il parsing e il loading


La seconda sottocartella rfd contiene vari moduli inerenti alla manipolazione delle RFD:
\begin{itemize}[noitemsep]
\let\labelitemi\labelitemii
    \item rfd{\_}extractor.py
    \item store{\_}and{\_}load.py
\end{itemize}

\paragraph{rfd{\_}extractor.py}
È contiene la classe RFDExtractor che si occupa di estrarre le RFD da un dataset
rfd{\_}extractor.py
\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
class RFDExtractor:
    ...
    def __init__(self, args, debug_mode=False) -> None:
    ...
    def __str__(self) -> str:
    ...
    def extract_args(self, args):
    ...
    def extract_hss(self, cols_count, lhs, rhs):
    ...
    def extract_sep_n_header(self, c_sep, csv_file, has_header):
    ...
    def check_correctness(self, has_dt, hss, index_col):
    ...
    def usage(self):
    ...
    def print_human(self, rfd_data_frame: pd.DataFrame):
    ...
    def get_rfd_dictionary_list(self) -> list:
    ...
\end{minted}
\caption{RFDExtractor}
\label{Code:6}
\end{listing}

Non saranno fornite particolari informazioni su questa classe , in quanto essa fa parte del progetto riguardante la ricerca di RFD , per ulteriori informazioni si veda \cite{tesinaIA}

\paragraph{store{\_}and{\_}load.py}
È un modulo che ha funzione di wrapping per l'algoritmo di ricerca di RFD.
Contiene due metodi:
\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
def diff(list1: list, list2: list):
...
def search_rfds(csvPath,name_rfds_file):
\end{minted}
\caption{Metodi store{\_}load{\_}rfds}
\label{Code:7}
\end{listing}

IL primo metodo "diff" prende in input due liste, e restituisce una lista di elementi che sono presenti nella prima ma non nella seconda.

Il secondo metodo richiama l'algoritmo di Ricerca delle RFD \footnote{In questo caso non è semplice richiamo di una funzione, bensì vengono richiamati una serie di metodi, e mano a mano vengono effettuate delle elaborazioni sui dati} e crea un file contente una lista di RFD. Prende in input il path del file contenente il Dataset, e una stringa che contiene il nome del file che incapsula le RFD. 

\subsection{Package query}
Nel package query vi sono tre moduli, tutte e tre si occupano di svolgere operazioni riguardanti le interrogazioni al dataset.
I tre moduli sono:
\begin{itemize}[noitemsep]
\let\labelitemi\labelitemii
    \item query.py
    \item relaxer.py
    \item slicer.py
\end{itemize}

\paragraph{relaxer.py}
Questo modulo contiene la classe QueryRelaxer, è una classe ausiliaria, contiene dei metodi statici che si occupano di rilassare la query rispetto ad una Relaxed Functional Dependency. La classe contiene i seguenti metodi:

\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
class QueryRelaxer:
    @staticmethod
    def drop_query_nan(rfds_df: pd.DataFrame, query: dict) 
                                            -> pd.DataFrame:
    ...
    @staticmethod
    def drop_query_rhs(rfds_df: pd.DataFrame, query: dict)
                                            -> pd.DataFrame:
    ...
    @staticmethod
    def sort_by_decresing_nan_incresing_threshold(rfds_df: 
                pd.DataFrame, query: dict) -> pd.DataFrame:
    ...
    @staticmethod
    def sort_by_increasing_threshold(rfds_df: pd.DataFrame,
        data_set: pd.DataFrame, query: dict) -> pd.DataFrame:
    ...
    @staticmethod
    def rfd_to_string(rfd: dict) -> str:
    ...
    @staticmethod
    def query_dict_to_expr(query: dict) -> str:
    ...
    @staticmethod
    def extend_query_ranges(query: dict, rfd: dict, 
            data_set: pd.DataFrame = None) -> dict:
    ...
    @staticmethod
    def similar_strings(source: str, data: pd.DataFrame,
                        col: str, threshold: int) -> list:
    ...
    @staticmethod
    def extract_value_lists(df: pd.DataFrame, columns: list):
    ...
\end{minted}
\caption{Classe Query Relaxer}
\label{Code:10}
\end{listing}

Il metodo drop{\_}query{\_}na(...) si occupa di eliminare tutte le RFD che possiedono valori NaN su attributi che sono contenuti anche nella query. Il metodo prende in input un pandas.Dataframe contenente la lista di RFD ed un dizionario contenente la query, restituisce un altro pandas.Dataframe.

Il metodo drop{\_}query{\_}rhs(...) si occupa di eliminare tutte le RFD che possiedono un attributo della query come parte RHS. Il metodo prende in input un pandas.Dataframe contenente la lista di RFD ed un dizionario contenente la query, restituisce un altro pandas.Dataframe.

Il metodo sort{\_}by{\_}decreasing{\_}nan{\_}incresing{\_}threshold(...), contiene un algoritmo di ordinamento. Il metodo prende in input un pandas.Dataframe ordina prima per numero di NaN presenti e poi per ordine crescente rispetto alla soglie, restituisce un pandas.Dataframe.

Il metodo sort{\_}by{\_}increasing{\_}threshold(...) , contiene un altro algoritmo di ordinamento, che è stato utilizzato solo nei test, dove è risultato poco producente. Il metodo prende in input un pandas.Dataframe e un dizionario contenente la query. Restitusce un altro pandas.Dataframe ordinato solo rispetto alle soglie degli attributi \footnote{In entrambi gli algoritmi di ordinamento vengono ordinate prima le soglie degli attributi contenuti nella query e poi in caso di valori uguali si ordina rispetto alle soglie degli altri attributi in LHS}

il metodo rfd{\_}to{\_}string(...) svolge un ruolo alquanto semplice, si occupa di convertire il formato delle RFD in un formato stringa facilmente leggibile.

Questo metodo converte il dizionario nel formato stringa richiesto dal Dataframe di Pandas.
Qui è importante fare delle precisazioni dato che in  questa parte del codice vengono definite le condizioni che si possono applicare alla query.
Nella riga 9 viene implementato la funzionalità di selezione di valori appartenenti ad un range. Possiamo effettuare una query del tipo: \\~\\
\centerline{SELECT * FROM dataset{\_}string WHERE height BETWEEN $value_1$ and $value_2$}
\\~\\
Nella riga 12 viene implementata la funzionalità di uguaglianza per int e float.
Nelle righe dal 13 a 22, viene implementata la funzione di uguaglianza con le stringhe, inoltre è stata implementata anche la funzionalità simil-SQL "LIKE". L'utente può quindi effettuare delle query non solo di uguaglianza, ma anche di contenimento. Ad esempio può chiedere tutte le stringhe che iniziamo per "mary" o che contengono la parola "ohn"

\begin{listing}[H]
\begin{minted}[bgcolor=black,frame=lines,linenos]{python}
def to_expression(self) -> str:
    last_key = list(self.keys())[-1]
    expr = ""
    for k, v in self.items():
        if isinstance(v, range):
            ...
        elif isinstance(v, dict):
            expr += " {} >= {} and {} <= {}".format(k, v['min'],
                                                    k, v['max'])
        elif isinstance(v, (int, float, list)):
            expr += " {} == {}".format(k, v)
        elif isinstance(v, str):
            if "%" in v:
                if v.startswith("%") and v.endswith("%"):
                    expr += k + ".str.contains('{}') ".format(v[1:-1])
                elif v.startswith("%"):
                    expr += k + ".str.endswith('{}') ".format(v[1::])
                elif v.endswith("%"):
                    expr += k + ".str.startswith('{}') ".format(v[:-1])
            else:
                expr += " {} == {}".format(k, v)

        if k is not last_key:
            expr += " and "
    return expr
\end{minted}
\caption{Metodo def{\_}to{\_}express()}
\label{Code:9}
\end{listing}

Il metodo extend{\_}query{\_}ranges(...) prende in input una query ed una RFD ed estende i range sugli attributi basandosi sulle soglie contenute nella RDF. Nel caso in qualche attributo della query è di tipo stringa vengono calcolate le stringhe simili e vengono utilizzare nella query estesa.
(vedi lavori futuri)


Il metodo similar{\_}string() prende in input una stringa, una pandas.Dataframe ed una soglia e si occupa di trovare nel database tutte le stringhe che differiscono di una soglia $\epsilon$. Restituisce un altro pandas.Dataframe 