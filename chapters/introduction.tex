\section{Incipit}

In un modello relazionale, la scoperta delle dipendenze funzionali assume un ruolo importante durante la progettazione o normalizzazione. Già da molto tempo queste dipendenze vengono utilizzate per migliorare la qualità dei database.
Negli ultimi anni abbiamo visto aumentare le fonti che generano dati, sia provenienti dal web, sia dalle reti di sensori o biologiche. All’aumento della quantità di dati generata non è corrisposto un mantenimento della stessa qualità. Ovviamente con moli di dati elevate è inconcepibile tentare di effettuare un cleaning dei dati manualmente. In quest'ottica è però possibile utilizzare le \emph{dipendenze funzionali approssimate} (AFD o RFD)\footnote{In tutta la tesi i termini ``Dipendenze Funzionali Approssimate'' e ``Dipendenze Funzionali Rilassate'' indicano lo stesso concetto.} per catturare delle consistenze più ampie nei dati.
Una volta individuate, queste RFD possono essere utilizzate sia per il data cleaning, sia in sistemi di rilassamento di query (query relaxation). 

In questo documento di tesi viene presentato un sistema basato su RFD per il rilassamento delle query. Nei sistemi di query è inopportuno che una interrogazione produca nessuna risposta oppure una risposta insoddisfacente. In questi casi è preferibile avere l'opzione di rilassare la query originale in modo che restituisca ulteriori risultati rilevanti che possono soddisfare le preferenze iniziali dell'utente. Qualsiasi motore di ricerca utilizza già un sistema per allargare il \emph{Result Set}\footnote{Per Result Set si intende l'insieme di tuple (o risultati) restituiti da un interrogazione.}, basta infatti allargare i range di ricerca per ottenere un Result Set più ampio. Spesso però includere risultati che differiscono molto da ciò che cerchiamo non è utile. In questo caso sarebbe preferibile effettuare una nuova ricerca con parametri differenti che però restituisca dei risultati attinenti a ciò che viene cercato inizialmente. Come si può effettuare questa modifica? Esiste qualche funzione che suggerisca cosa cercare quando su Amazon scrivendo ``PC Gaming Dell'' non escono risultati soddisfacenti? Ebbene sì, un modo c'è! Implementando questa tecnica si può ricevere un suggerimento di ricerca come ``I7 gtx 1080 SSD 256''. Questo tipo di sistema è in grado di capire che chi è interessato ad un Computer da Gaming della Dell probabilmente sarà attratto anche da un computer che possiede un processore i7, una scheda video gtx 1080 ed una SSD.
Questo link fra ``PC Gaming Dell'' e ``I7 gtx 1080 SSD 256'' viene scoperto dalle RFD.

\section{Utilizzo delle FD in contesti particolari}

In alcuni contesti non è possibile utilizzare le FD canoniche, in quanto il concetto di uguaglianza non esiste. In questi casi vengono applicate delle funzioni di similarità ad-hoc. Gli esempi più banali cominciano dalle stringhe, dove per misurare la differenza fra due di esse si usa la distanza di \emph{Levenshtein}\footnote{La distanza di Levenshtein è una misura per la differenza di stringhe, dove si tiene conto delle lettere mancanti, sbagliate o superflue.}, o dalla data  dove per effettuare un confronto bisogna implementare il calendario gregoriano. In alcuni ambiti invece le funzioni di similarità aumentano di complessità, si pensi a come può essere strutturata una funzione di similarità in un sistema multimediale. In molti casi è opportuno implementare una fonte di conoscenza esterna, come ad esempio in un database riguardante le città europee dove conviene utilizzare una funzione che ne misuri la distanza spaziale piuttosto che la somiglianza lessicale. Le FD canoniche non ammettono l'esistenza di un funzione di similarità, in questo caso si preferiscono utilizzare le RFD.

\section{Ricerca di RFD}
Gli algoritmi di ricerca delle RFD o AFD hanno complessità elevata dato lo spazio di ricerca dei possibili vincoli di similarità, la complessità è riconducibile al problema di trovare un insieme ricoprente minimale di RFD verificate per una relazione $r$. Ciò al momento pone un forte fardello sullo sviluppo di applicazioni che sfrutta le RFD. Con database che superano le milioni di righe è ancora svantaggioso l’approccio. Per tale motivo in questo lavoro di tesi sono stati utilizzati DataSet non troppo grandi. Al momento vi sono alcuni team che stanno lavorando alla parallelizzazione dell'algoritmo di ricerca delle RFD, e si sono già ottenuti ottimi risultati durante la fase di testing (il miglioramento delle performance è stato di circa il 75\%).


\section{Studi Preliminari}
Prima di cominciare il lavoro relativo al sistema di Query Relaxation è stato necessario studiare il linguaggio Python.
La scelta è ricaduta su Python per tre motivi principali:
\begin{enumerate}
    \item È un linguaggio che seppur orientato agli oggetti, possiede delle librerie quali: Cython, ecc.. le quali permettono di aumentare la velocità eseguendo il codice in C.
    \item Il sistema esistente di discovery di RFD è stato sviluppato in Python, ed anche se il nostro modulo ne è indipendente, si è preferito utilizzare lo stesso linguaggio.
    \item Per ampliare le competenze, possedere un progetto sviluppato in Python.
\end{enumerate}
Oltre le principali tecniche di programmazione sono stati utilizzati alcune particolari funzionalità del Python:

\begin{itemize}
\item \emph{List Comprehensions}: Uno strumento che permette di creare in modo conciso e conveniente delle liste partendo da una sequenza di valori esistenti, inoltre le \emph{comprehension} permettono anche di filtrare e trasformare gli elementi tramite costrutti if.
Normalmente per creare delle liste si procede in questo modo:
\begin{listing}[H]
\begin{minted}[frame=lines,linenos]{python}
newList = []
for i in oldList:
    if filter(i):
        newList.append(expressions(i))
\end{minted}
\end{listing}

Grazie alle List Comprehension il tutto si riduce ad un riga di codice:
\mint{python}|newList = [expression(i) for i in oldList if filter(i)]|

\item \emph{Lambda Functions}: Python supporta la creazione di funzioni anonime \footnote{Ossia funzioni che non sono legate ad un nome.} a Runtime, usando dei costrutti chiamati ``lambda''.  
\begin{listing}[H]
\begin{minted}[frame=lines,linenos]{python}
# Esempio di utilizzo delle lambda functions

double = lambda x: x * 2

# Output: 10
print(double(5))
\end{minted}
\end{listing}
\item Negative Indexing: Per ottenere un elemento da una lista è possibile utilizzare degli indici negativi ottenendo (in una lista di k elementi) il (k-n)esimo elemento
\begin{listing}[H]
\begin{minted}[frame=lines,linenos]{python}
>>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> a[-1]
10
\end{minted}
\end{listing}
\item Iterazione su chiave-valore: è possibile iterare sui dizionari ottenendo contemporaneamente chiave e valore.
\begin{listing}[H]
\begin{minted}[frame=lines,linenos]{python}
>>> m = {'a': 1, 'b': 2, 'c': 3, 'd': 4}
>>> for k, v in m.iteritems():
...     print '{}: {}'.format(k, v)
...
a: 1
c: 3
\end{minted}
\end{listing}

\end{itemize}

Oltre le librerie standard sono stati utilizzati alcuni Framework esterni: 
\begin{itemize}
\item \emph{Pandas}: È una libreria che include delle strutture dati e tool di analisi facili da usare e fortemente ottimizzate. 
\item \emph{Numpy}: È un package dedicato all'elaborazione scientifica sul linguaggio Python.
\end{itemize}
All'infuori delle conoscenze legate ai linguaggi di programmazione, è stato necessario leggere e studiare vari documenti legati al mondo delle dipendenze funzionali. La maggior parte del tempo è stata impiegata per capire in che modo utilizzare le RFD. 
È stato necessario comprendere il funzionamento (visione black-box) dell’algoritmo utilizzato nel progetto di IA. 

\section{Nozioni Preliminari}
Prima di esporre le RFD è necessario introdurre alcuni concetti preliminari.

\paragraph{Schema di relazione}
Uno schema di relazione è costituito da un simbolo $R$, detto nome della relazione, e da un insieme di attributi $X = \{A_1,A_2,...,A_n\}$, di solito indicato
con $R(X)$. A ciascun attributo $A \in X$ e associato un dominio $dom(A)$.
Uno schema di base di dati è un insieme di schemi di relazione con nomi
diversi:
\\~\\
\centerline{$R = \{ R_1(X_1),R_2(X_2),\ldots,R_n(X_n)\}$.}
\\~\\
Una relazione su uno schema $R(X)$ è un insieme $r$ di tuple su $X$. Per
ogni istanza $r \in R(X)$, per ogni tupla $t \in r$ e per ogni attributo $A \in X$,
$t[A]$ rappresenta la proiezione di $A$ su $t$. In modo analogo, dato un insieme
di attributi $Y \subseteq X$, $t[Y]$ rappresenta la proiezione di $Y$ su $t$.\cite{libroCeri}


\begin{table}[H]
    \centering
    \begin{tabular}{ | l | l | l | l |}
        \hline
        Matricola & Cognome & Nome & Data di nascita\\
        \hline
        276545 & Rossi & Maria & 25/11/1991 \\ 
        485745 & Neri & Anna & 23/04/1992 \\ 
        200768 & Verdi & Fabio & 12/02/1992 \\
        587614 & Rossi & Luca & 10/10/1991 \\
        937653 & Bruni & Mario & 01/12/1991 \\
        \hline
    \end{tabular}
    \caption{Esempio di schema di relazione}
    \label{tab:table example}
\end{table}

\section{Software di ricerca di RFD}
Il software sviluppato per funzionare necessita di una lista di RFD, prese in input da file. Nel caso in cui questa lista non fosse disponibile, ci si avvale di un algoritmo di ricerca.
Il progetto riguardante la ricerca di RFD è stato sviluppato durante il corso di Intelligenza Artificiale dell’anno accademico 2016/2017.
L’algoritmo per scoprire le RFD è di tipo top-down \footnote{I metodi top-down effettuano una generazione di possibili FD per ogni livello e gradualmente controllano se esse si verificano.}.
Inizialmente si genera un grafo di attributi, definito in una struttura a lattice, dove vengono considerati tutti i possibili sottoinsiemi di attributi. Dato uno schema relazionale
\\~\\ 
\centerline{$R=(A_1,A_2,...,A_n)$}
\\~\\
abbiamo che :
\begin{itemize}[noitemsep]
\item livello 0: non contiene alcun attributo
\item livello 1: contiene i singleton di ogni attributi
\item livello 2: contiene tutte le possibili coppie di attributi
\item livello \ldots
\item livello n: contiene tutto l’insieme di attributi.
\end{itemize}
Ogni sottoinsieme contenuto in uno di questi livelli è candidato per una possibile RFD.
L’algoritmo parte del livello 0  e per ogni livello controlla, per tutti i sottoinsiemi $X \in L_r$, l’esistenza di dipendenze funzionali.
Il funzionamento preciso è definito da:
per ogni $A \in X$ si cerca di controllare se la $FD$  $X\setminus A \xrightarrow{}  A $ vale. Questo tipo di algoritmo ha complessità esponenziale.

Di questo software non ne è stato studiato il funzionamento white-box, bensì si è preferito un approccio black-box focalizzandosi su cosa prende in input e cosa restituisce in output.

\subsection{Input}
Il programma prende in input un Dataset in formato csv.
Il Dataset possiede una prima riga che funge da header, ogni nome di attributo è separato da un carattere speciale. \footnote{Solitamente viene utilizzato il simbolo  ; .}
Ogni riga del file csv costituisce una tupla.

\subsection{Output}
Una volta eseguito l’algoritmo di ricerca l’output, ossia le RFD trovate, viene stampato sul terminale. Le RFD sono raggruppate utilizzando come pivot l’attributo che si trova nel lato RHS\footnote{Per RHS si intende il lato destro di una dipendenza funzionale rilassata.} della RFD. Il software restituisce le RFD in due formati:
Il primo è sotto forma di Pandas Dataframe:
\begin{table}[H]
    \centering
    \begin{tabular}{l  l  l  l  l }
     RHS & $attr_1$ & $attr_1$ &$attr_{\ldots}$ & $attr_n$ \\
    \hline
    0 & $v_{11}$ & $v_{12}$ & $v_{1\ldots}$ & $v_{1n}$\\
    1 & $v_{21}$ & $v_{22}$ & $v_{2\ldots}$ & $v_{2n}$\\
    $\ldots$ & $v_{\ldots1}$ & $v_{\ldots2}$ & $v_{\ldots}$ & $v_{\ldots n}$\\
    m & $v_{m1}$ & $v_{m2}$ & $v_{m\ldots}$ & $v_{mn}$\\
    \end{tabular}
    \caption{Pandas Dataframe}
    \label{tab:pandas_dataframe}
\end{table}


Mentre il secondo formato ottenuto avviando il programma specificando l’opzione “-human” è in un formato leggibile ma non portabile:
\\~\\
\centerline{$attr_1(\leq soglia_1),attr_2(\leq soglia_2),\ldots,{attr_n}(\leq soglia_n)->RHS(\leq soglia_{rhs})$}
\\~\\
I tempi di esecuzione di questo algoritmo di ricerca sono abbastanza elevati, già con Dataset che superano il migliaio di righe i tempi non si misurano più in ore ma in giorni. Inoltre si è rilevato che con Dataset costituiti da poche righe ma da molti attributi i tempi di calcolo aumentano esponenzialmente.